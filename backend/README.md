# VaidyaAI Backend

FastAPI backend for the VaidyaAI Medical AI Platform. Provides comprehensive APIs for tutoring, study tools, clinical reasoning, and the Interactive Learning Assistant (Teach-Back Mode).

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+
- PostgreSQL (via Supabase)
- Virtual environment

### Setup

1. **Create virtual environment**:
```bash
python -m venv venv
```

2. **Activate virtual environment**:
- Windows: `venv\Scripts\activate`
- Unix/MacOS: `source venv/bin/activate`

3. **Install dependencies**:
```bash
pip install -r requirements.txt
```

4. **Configure environment**:
```bash
cp .env.example .env
# Edit .env with your credentials:
# - SUPABASE_URL and SUPABASE_SERVICE_KEY
# - LLM API keys (TEACH_BACK_PRIMARY_LLM_KEY, TEACH_BACK_FALLBACK_LLM_KEY)
# - LOCAL_MODELS_DIR (default: /local_models)
```

5. **Run development server**:
```bash
# Standard way
uvicorn main:app --reload

# Or with colored logging (recommended)
./start_server.sh          # Linux/macOS
start_server.bat           # Windows

# Custom port
./start_server.sh 8080
```

API available at: http://localhost:8000
API Docs: http://localhost:8000/docs

## ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ main.py                      # FastAPI application entry point
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ pytest.ini                   # Pytest configuration
â”‚
â”œâ”€â”€ config/                      # Configuration
â”‚   â”œâ”€â”€ colored_logging.py       # Enhanced logging with colors
â”‚   â”œâ”€â”€ model_config.py          # Model configuration
â”‚   â”œâ”€â”€ teach_back_limits.json   # Rate limits per plan
â”‚   â””â”€â”€ teach_back_retention.json # Data retention policies
â”‚
â”œâ”€â”€ services/                    # Business logic services
â”‚   â”œâ”€â”€ auth.py                  # Authentication & authorization
â”‚   â”œâ”€â”€ chat.py                  # Chat/tutoring service
â”‚   â”œâ”€â”€ clinical.py              # Clinical reasoning
â”‚   â”œâ”€â”€ clinical_reasoning_engine.py  # Advanced clinical logic
â”‚   â”œâ”€â”€ study_tools.py           # Study tools (flashcards, MCQs, etc.)
â”‚   â”œâ”€â”€ documents.py             # Document processing & RAG
â”‚   â”œâ”€â”€ rate_limiter.py          # Rate limiting for core features
â”‚   â”œâ”€â”€ model_router.py          # LLM provider routing
â”‚   â”œâ”€â”€ model_usage_logger.py    # Usage tracking
â”‚   â”œâ”€â”€ admin.py                 # Admin operations
â”‚   â”œâ”€â”€ audit.py                 # Audit logging
â”‚   â”œâ”€â”€ notifications.py         # User notifications
â”‚   â”œâ”€â”€ payments.py              # Payment processing
â”‚   â”œâ”€â”€ scheduler.py             # Background jobs
â”‚   â”œâ”€â”€ health_monitor.py        # Health checks
â”‚   â”œâ”€â”€ maintenance.py           # Maintenance mode
â”‚   â”œâ”€â”€ commands.py              # Command execution
â”‚   â”œâ”€â”€ text_formatter.py        # Text formatting utilities
â”‚   â””â”€â”€ providers/               # LLM provider integrations
â”‚       â”œâ”€â”€ openrouter.py        # OpenRouter API
â”‚       â”œâ”€â”€ gemini.py            # Google Gemini
â”‚       â””â”€â”€ huggingface.py       # Hugging Face
â”‚
â”œâ”€â”€ teach_back/                  # Interactive Learning Assistant
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models.py                # Pydantic data models
â”‚   â”œâ”€â”€ session_manager.py       # Session lifecycle
â”‚   â”œâ”€â”€ state_machine.py         # State management
â”‚   â”œâ”€â”€ rate_limiter.py          # Independent rate limiting
â”‚   â”œâ”€â”€ voice_processor.py       # STT/TTS integration
â”‚   â”œâ”€â”€ llm_orchestrator.py      # Multi-role LLM coordination
â”‚   â”œâ”€â”€ data_storage.py          # Database operations
â”‚   â”œâ”€â”€ integrations.py          # Integration with other systems
â”‚   â”œâ”€â”€ retention_policy.py      # Data retention & cleanup
â”‚   â”œâ”€â”€ error_codes.py           # Error code definitions
â”‚   â”œâ”€â”€ routes.py                # API endpoints
â”‚   â”œâ”€â”€ admin_routes.py          # Admin controls
â”‚   â”œâ”€â”€ README.md                # Teach-back documentation
â”‚   â””â”€â”€ roles/                   # AI role implementations
â”‚       â”œâ”€â”€ student_persona.py   # Curious learner role
â”‚       â”œâ”€â”€ evaluator.py         # Error detection role
â”‚       â”œâ”€â”€ controller.py        # Flow control role
â”‚       â””â”€â”€ examiner.py          # OSCE examination role
â”‚
â”œâ”€â”€ middleware/                  # Custom middleware
â”‚   â”œâ”€â”€ admin_auth.py            # Admin authentication
â”‚   â”œâ”€â”€ feature_toggle.py        # Feature flag middleware
â”‚   â””â”€â”€ maintenance.py           # Maintenance mode middleware
â”‚
â”œâ”€â”€ database/                    # Database utilities
â”‚   â”œâ”€â”€ COMPLETE_DATABASE_SCHEMA.sql  # Full schema
â”‚   â”œâ”€â”€ migrations/              # Database migrations
â”‚   â””â”€â”€ README.md                # Database documentation
â”‚
â””â”€â”€ tests/                       # Test suite
    â”œâ”€â”€ conftest.py              # Pytest configuration
    â”œâ”€â”€ unit/                    # Unit tests
    â”œâ”€â”€ integration/             # Integration tests
    â””â”€â”€ property/                # Property-based tests
```

## ğŸ”§ Configuration

### Environment Variables

**Required**:
```bash
# Supabase
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_SERVICE_KEY=your-service-key

# LLM Configuration (Teach-Back)
TEACH_BACK_PRIMARY_LLM_PROVIDER=openrouter
TEACH_BACK_PRIMARY_LLM_MODEL=anthropic/claude-3.5-sonnet
TEACH_BACK_PRIMARY_LLM_KEY=sk-...
TEACH_BACK_FALLBACK_LLM_KEY=hf_...

# Local Models
LOCAL_MODELS_DIR=/local_models
```

**Optional**:
```bash
# Feature Flags
TEACH_BACK_ENABLED=true
TEACH_BACK_VOICE_ENABLED=true

# Integration Endpoints
FLASHCARD_SERVICE_URL=http://localhost:8000/api/flashcards
WEAK_AREA_SERVICE_URL=http://localhost:8000/api/weak-areas
STUDY_PLANNER_SERVICE_URL=http://localhost:8000/api/study-planner
MCQ_SERVICE_URL=http://localhost:8000/api/mcqs

# Logging
LOG_LEVEL=INFO
```

### Configuration Files

**`config/teach_back_limits.json`** - Rate limits per plan:
```json
{
  "free": {"sessions_per_day": 0, "voice_sessions_per_day": 0},
  "student": {"sessions_per_day": 5, "voice_sessions_per_day": 2},
  "pro": {"sessions_per_day": 20, "voice_sessions_per_day": 10},
  "admin": {}
}
```

**`config/teach_back_retention.json`** - Data retention policies:
```json
{
  "free": 7,
  "student": 30,
  "pro": 90,
  "admin": 365
}
```

## ğŸ¨ Colored Logging

The backend features beautiful colored console output for better readability:

- **Color-coded log levels**: DEBUG (Cyan), INFO (Green), WARNING (Yellow), ERROR (Red), CRITICAL (Magenta)
- **HTTP status codes**: Automatically colored (2xx=Green, 3xx=Yellow, 4xx=Red, 5xx=Magenta)
- **Enhanced context**: Timestamps, module names, function names
- **Startup banner**: Beautiful ASCII art banner on server start

### Configuration

Colored logging is configured in `config/colored_logging.py`. Adjust log level in `main.py`:

```python
from config.colored_logging import setup_colored_logging
import logging

setup_colored_logging(level=logging.DEBUG)    # Show all logs
setup_colored_logging(level=logging.INFO)     # Default
setup_colored_logging(level=logging.WARNING)  # Only warnings+
```

## ğŸ“š API Documentation

### Interactive Documentation
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Core Endpoints

**Authentication**:
- `POST /api/auth/login` - User login
- `POST /api/auth/register` - User registration
- `POST /api/auth/logout` - User logout

**Chat/Tutoring**:
- `POST /api/chat/message` - Send chat message
- `GET /api/chat/history` - Get chat history
- `POST /api/chat/clear` - Clear chat history

**Study Tools**:
- `GET /api/study-tools/flashcards` - Get flashcards
- `POST /api/study-tools/flashcards` - Create flashcard
- `GET /api/study-tools/mcqs` - Get MCQs
- `POST /api/study-tools/mcqs` - Create MCQ

**Clinical Reasoning**:
- `POST /api/clinical/case` - Get clinical case
- `POST /api/clinical/reasoning` - Get reasoning support
- `GET /api/clinical/progress` - Get progress

**Interactive Learning (Teach-Back)**:
- `POST /api/teach-back/sessions` - Create session
- `GET /api/teach-back/sessions/{id}` - Get session
- `POST /api/teach-back/sessions/{id}/input` - Process input
- `POST /api/teach-back/sessions/{id}/end` - End session
- `GET /api/teach-back/quota` - Get quota info

**Admin**:
- `GET /api/admin/users` - List users
- `POST /api/admin/feature-toggle` - Toggle features
- `GET /api/admin/usage` - Usage statistics
- `POST /api/admin/maintenance` - Maintenance mode

## ğŸ§ª Testing

### Run All Tests
```bash
pytest
```

### Run Specific Test Categories

**Unit Tests**:
```bash
pytest tests/unit/ -v
```

**Integration Tests**:
```bash
pytest tests/integration/ -v
```

**Property-Based Tests** (29 properties, 100 iterations each):
```bash
pytest tests/property/ -v
pytest tests/property/test_teach_back_properties.py -v  # Teach-back only
```

### Test Coverage
```bash
pytest --cov=backend --cov-report=html
# Open htmlcov/index.html in browser
```

### Run Tests in Watch Mode
```bash
pytest-watch
```

## ğŸ” Security

### Authentication
- JWT tokens via Supabase Auth
- Token validation on all protected endpoints
- Automatic token refresh

### Authorization
- Role-based access control (RBAC)
- Admin, teacher, student roles
- Feature-level permissions

### Data Protection
- End-to-end encryption for sensitive data
- Secure password hashing
- SQL injection prevention (ORM usage)
- CORS protection

### Rate Limiting
- Per-user rate limits
- Per-feature quotas
- Plan-based limits
- Admin overrides

## ğŸ“Š Monitoring

### Health Checks
```bash
curl http://localhost:8000/health
```

### Key Metrics
- Session creation/completion rates
- LLM provider performance
- Error rates by type
- User engagement metrics
- Feature usage by plan

### Logging
- Structured logging with context
- Error tracking and alerting
- Audit trail for admin actions
- Performance metrics

## ğŸš€ Deployment

### Docker
```bash
docker build -t vaidyaai-backend .
docker run -p 8000:8000 --env-file .env vaidyaai-backend
```

### Environment Setup
1. Set all required environment variables
2. Download local models: `bash scripts/download_teach_back_models.sh`
3. Run database migrations: `python run_migration.py`
4. Start server: `uvicorn main:app`

### Production Checklist
- [ ] All environment variables set
- [ ] Database migrations applied
- [ ] Local models downloaded
- [ ] SSL/TLS configured
- [ ] Monitoring enabled
- [ ] Backup strategy in place
- [ ] Error tracking configured

## ğŸ“– Additional Documentation

- **Teach-Back Module**: `teach_back/README.md`
- **Database Schema**: `database/COMPLETE_DATABASE_SCHEMA.sql`
- **Deployment Guide**: `../docs/teach_back_deployment.md`
- **Design Document**: `../.kiro/specs/medical-ai-platform/design.md`

## ğŸ¤ Contributing

1. Create feature branch: `git checkout -b feature/your-feature`
2. Write tests for changes
3. Run tests: `pytest`
4. Ensure coverage: `pytest --cov`
5. Commit with clear messages
6. Push and create PR

## ğŸ“ Code Style

- **Python**: PEP 8 (use `black` for formatting)
- **Type Hints**: Required for all functions
- **Docstrings**: Google-style docstrings
- **Logging**: Use structured logging

## ğŸ› Troubleshooting

### Common Issues

**Port already in use**:
```bash
# Find process using port 8000
lsof -i :8000
# Kill process
kill -9 <PID>
```

**Database connection failed**:
- Check SUPABASE_URL and SUPABASE_SERVICE_KEY
- Verify network connectivity
- Check Supabase project status

**LLM API errors**:
- Verify API keys are correct
- Check rate limits
- Ensure fallback LLM is configured

**Voice processing errors**:
- Verify LOCAL_MODELS_DIR exists
- Check model files are downloaded
- Ensure sufficient disk space

## ğŸ“ Support

For issues or questions, refer to:
- API Documentation: http://localhost:8000/docs
- Design Document: `.kiro/specs/medical-ai-platform/design.md`
- Teach-Back Guide: `teach_back/README.md`
